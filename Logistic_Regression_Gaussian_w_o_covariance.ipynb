{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression_Gaussian_w/o covariance.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nDZwb6yP73R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from random import gauss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ull8htSIBRlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian_generator(mu, sigma):\n",
        "  data = []\n",
        "\n",
        "  for i in range(100):\n",
        "    data.append(gauss(mu, sigma))\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L9aWqz6QA2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_0_mu = 5\n",
        "cls_1_mu = 8\n",
        "cls_0_sigma = 0.6\n",
        "cls_1_sigma = 0.5\n",
        "\n",
        "class_0 = gaussian_generator(cls_0_mu, cls_0_sigma)\n",
        "class_1 = gaussian_generator(cls_1_mu, cls_1_sigma)   \n",
        "\n",
        "plt.hist(class_0, color = \"skyblue\", bins = 100)\n",
        "plt.hist(class_1, color = \"red\", bins = 100)\n",
        "plt.title(\"data distribution\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOMrtQ72NLSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "940c175c-7843-446b-ba41-6ac03a461272"
      },
      "source": [
        "x = np.array(class_0 + class_1).reshape(len(class_0) + len(class_1), 1)\n",
        "y = np.concatenate((np.zeros(len(class_0)), np.ones(len(class_1))), axis= 0).reshape(len(class_0) + len(class_1), 1)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 1)\n",
            "(200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcInztAnQA71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, train_data, label_data, lr = 1e-2, delta = 1e-7, max_iter = 10000, cost_threshold = 1e-2, class_threshold = 0.5, verbose = True):\n",
        "    self.x_data = train_data\n",
        "    self.y_data = label_data\n",
        "    self.lr = lr\n",
        "    self.max_iter = max_iter\n",
        "    self.delta = delta\n",
        "    self.cost_threshold = cost_threshold\n",
        "    self.class_threshold = class_threshold\n",
        "    self.verbose = verbose\n",
        "  \n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "  def loss_func(self, h, y): \n",
        "    # !log(0)\n",
        "    return - np.sum(y * np.log(h + self.delta) + (1 - y)*np.log((1-h) + self.delta))\n",
        "\n",
        "  def train(self):\n",
        "\n",
        "    self.w = np.random.rand(1,1)\n",
        "    self.b = np.random.rand(1)\n",
        "\n",
        "    w_list = []\n",
        "\n",
        "    for i in range(self.max_iter):\n",
        "\n",
        "      w_list.append(self.w)\n",
        "\n",
        "      z = np.dot(self.x_data, self.w) + self.b # (100,)\n",
        "      h = self.sigmoid(z) # predicted possibility of x, (10,)\n",
        "      \n",
        "      diff = h - self.y_data #(100, 100)\n",
        "\n",
        "      cost = self.loss_func(h, self.y_data)\n",
        "\n",
        "      gradient = np.dot(self.x_data.transpose(), diff) #(1, 100)\n",
        "\n",
        "      self.w -= self.lr * gradient / self.x_data.shape[0]\n",
        "      self.b -= self.lr * np.mean(diff) / self.x_data.shape[0]\n",
        "\n",
        "\n",
        "      if cost < self.cost_threshold:\n",
        "        return False\n",
        "\n",
        "      if (self.verbose == True and i %100000 == 0):\n",
        "        print('cost of {} iteration: {}'.format(i, cost))\n",
        "\n",
        "    # plot w\n",
        "    y = np.arrange(self.max_iter)  \n",
        "    plt.plot(w_list, y)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "    z = np.dot(x, self.w) + self.b\n",
        "    h = self.sigmoid(z) # predicted possibility of x\n",
        "\n",
        "    h_class = 1 if h > self.class_threshold else 0\n",
        "\n",
        "\n",
        "    return h, h_class\n",
        "\n",
        "\n",
        "  def getwb(self):\n",
        "    return self.w, self.b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV4YpE42QBBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  LR = LogisticRegression(train_data = x, label_data = y, lr = 0.001, max_iter = 10000000)\n",
        "\n",
        "  LR.train()\n",
        "\n",
        "  (predicted_prob, predicted_class) = LR.predict(2)\n",
        "  print(predicted_prob, predicted_class)\n",
        "\n",
        "  (predicted_prob, predicted_class) = LR.predict(8)\n",
        "  print(predicted_prob, predicted_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdqV5xRlQBGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(w, b) = LR.getwb()\n",
        "print(w, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpzRJGFXQBAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg8L7mUmQA-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHzKSUpqZ3ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3BzjBLXRDlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}